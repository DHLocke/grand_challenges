---
title: "04_filter_trees_HOLC"
author: "Kelsey McGurrin Dexter H. Locke"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

  
## 0 set up: load libraries, custom functions, set defaults
```{r}

# load libraries
# packages we'll be using
packs <- c(
  'tidyverse'         # a must have!
  , 'tidylog'         # makes things very verbose for 2x checking 
  , 'magrittr'        # all of the pipes
  , 'janitor'         # cleans things up
  , 'sf'              # spatial support
  #, 'tidycensus'      # Census access
  , 'mapview'         # webmaps
  , 'tictoc'          # times things
  , 'beepr'           # makes noises
  )         

# check for all of the libraries
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

# load them
vapply(packs, library, character.only = TRUE, logical(1), logical.return = TRUE, quietly = TRUE)



# keep random things consistent
# set.seed(19870630) # needed?


# redlining colors
holc_pal <- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              #, '#A9A9A9'
              ) # dark gray)

holc_pal_f<- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              , '#A9A9A9'
              , '#000000')


# set custom function for getting spatial data
see_sf <- function(){
# what's in memory that are sf - spatial features?
keep(eapply(.GlobalEnv, class),      # gets the objects in the global environment
     ~ any(str_detect(., "sf"))) %>% # selects elements with sf in them
    names(.) %>% as.character(.)     # my simple features
}

see_sf() -> sf_in_memory

# what are the spatial references of those SF classes?
mget(sf_in_memory) %>% purrr::map(~st_crs(.x)$epsg) %>% unlist() #%>% View()


# # get file size

# custom function for "Not In"
`%nin%` <- Negate(`%in%`)


# fixes mapview
mapviewOptions(fgb = FALSE)

```


## 1 read in HOLC polygons
```{r}
#define new groups for HOLC
(holc_lu <- 
  tribble(
    ~grade, ~grade_group,
    "A",    "AB",
    "B",    "AB",
    "C",    "C",
    "D",    "D",
    NA,     "industrial"
  ))


#read in shapefile, add new column
(holc <- st_read('output_tables/baci_holc_polygons_2024-02-20.gpkg', as_tibble = TRUE) %>% 
    left_join(holc_lu,by="grade"))

#double check reclassification
holc %>%
  st_drop_geometry() %>%
  tabyl(grade,grade_group)

holc %>% 
  #filter(is.na(grade)) %>% 
  mapview(zcol="grade_group")

```


# 2 get species of trees to focus on
```{r}

species_to_include <- 
  googlesheets4::read_sheet('https://docs.google.com/spreadsheets/d/18K_M4e84m2yl0LYTxfubLhMRby1d5Uoosd1fJShEsH8/edit#gid=1234522482'
                            , sheet = 'Narrowed list')

```



# 3 bring in trees and match to HOLC polygons
```{r}

tic(); trees <-
  st_read("G:/Shared drives/Grand Challenges/data/bc_forestry_trees_12232020/bc_forestry_trees_12232020.shp") |> 
  # st_read("/Users/dlocke/evo/AFRI_local/input_data/bc_forestry_trees_12232020/bc_forestry_trees_12232020.shp") |> # Dexter path
  filter(SPP %in% species_to_include$SPP & # species of interest to Karin
           DBH < 5 & # trees that were small in 2018
           CONDITION %nin% c("Dead","Absent","Stump","Sprouts","NA","N/A","Stump w") # only healthy-ish trees
         ) |> 
  st_transform(st_crs(holc)) |> 
  st_join(holc |> select(area_id, grade_group), left = TRUE) |> 
  mutate(grade_group = ifelse(is.na(grade_group), 'not classified by HOLC', grade_group)) |>
  filter(grade_group %in% c("AB","C","D")); toc() #takes 1 min to run

# did that work?
trees |> st_drop_geometry() |> tabyl(SPP,grade_group)
trees |> glimpse()
trees |> 
  sample_n(1000) |> 
  mapview(zcol = 'grade_group')
  
trees |> 
  filter(SPP == "Ulmus americana") |> 
  mapview(zcol = 'grade_group')

```



# 4 add in neighborhood heat data
```{r}
heat_summary <- read_csv('output_tables/heat_summary_2024-02-27.csv') |> 
    rename(area_id = polygon_id)

trees<- trees |> 
  left_join(heat_summary, by = 'area_id')

# did that work?
trees |> st_drop_geometry() |> tabyl(mean_temp_C,grade_group)

trees |> 
  sample_n(1000) |> 
  mapview(zcol = 'mean_temp_C')+mapview(filter(holc,grade_group != "industrial"),zcol="grade_group")
```


# 5 export 
```{r}

#TO DO FIX ME
# what is the best way to share/export this info? probably want one map per tree species for tree selection
# once trees are selected, one map with everything?
trees |> 
  write_csv(paste0('output_tables/all_potential_trees_', Sys.Date(), '.csv'))

```


# end



