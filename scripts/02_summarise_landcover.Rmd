---
title: "02_summarise_landcover"
author: "Kelsey McGurrin Dexter H. Locke"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

  
## 0 set up: load libraries, custom functions, set defaults
```{r}

# load libraries
# packages we'll be using
packs <- c(
  'tidyverse'         # a must have!
  , 'tidylog'         # makes things very verbose for 2x checking 
  , 'magrittr'        # all of the pipes
  , 'janitor'         # cleans things up
  , 'sf'              # spatial support
  , 'tidycensus'      # Census access
  , 'mapview'         # webmaps
  , 'tictoc'          # times things
  , 'beepr'           # makes noises
  , 'foreign'         # read DBF files
  )         

# check for all of the libraries
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

# load them
vapply(packs, library, character.only = TRUE, logical(1), logical.return = TRUE, quietly = TRUE)



# keep random things consistent
# set.seed(19870630) # needed?


# redlining colors
holc_pal <- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              #, '#A9A9A9'
              ) # dark gray)

holc_pal_f<- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              , '#A9A9A9'
              , '#000000')


# set custom function for getting spatial data
see_sf <- function(){
# what's in memory that are sf - spatial features?
keep(eapply(.GlobalEnv, class),      # gets the objects in the global environment
     ~ any(str_detect(., "sf"))) %>% # selects elements with sf in them
    names(.) %>% as.character(.)     # my simple features
}

see_sf() -> sf_in_memory

# what are the spatial references of those SF classes?
mget(sf_in_memory) %>% purrr::map(~st_crs(.x)$epsg) %>% unlist() #%>% View()


# # get file size

# custom function for "Not In"
`%nin%` <- Negate(`%in%`)


# fixes mapview
mapviewOptions(fgb = FALSE)

```


## 1 read in the land cover spatial reference system
```{r}

# how does this match up with the land cover data?

# download data to the lcc_path folder below
# you have to go to the map, click on baltimore city county, and then a list of available downloads pops up.
# select "Land Cover Change"
# https://cicgis.org/portal/apps/webappviewer/index.html?id=bdf7ca3e249a40fd9a9d83d6e16100ea&extent=-88.252,35.0981,-62.3462,45.7489

# for whole state of maryland, download here
# https://www.sciencebase.gov/catalog/item/63334dc3d34e900e86c62264 


#lcc_path <- '/Users/dlocke/tree_temp_change/large_data/balt_24510_lc_change_2013_2018'
#lcc_path <- '/Users/mschaef9/Documents/grand challenges git/grand_challenges_large'
lcc_path <- '~/Documents/grand challenges git/grand_challenges_large'

(lcc <- raster::raster(paste0(lcc_path, '/balt_24510_landcoverchange_20132018.tif')))

# Making a lookup table between raster code values, land cover change, land cover per year, and color pallette
(
  lcc_key <-
    foreign::read.dbf(paste0(lcc_path,'/md_lc-change_2013-2018_2022-Edition.tif.vat.dbf')) |>
    tidylog::select(ID = Value, LCChange, ChangeType, Red : Alpha) |>
    mutate(LCChange = str_replace_all(LCChange, 'Scrub\\\\Shrub', 'Scrub Shrub')) |>
    separate(LCChange, into = c('y_2013', 'y_2018'), sep = ' to ', remove = FALSE) |>
    mutate(  y_2018 = ifelse(is.na(y_2018), y_2013, y_2018) # stability
           , tcc_class =
               case_when(
                   # y_2013 == 'Tree Canopy' & y_2018 == 'Tree Canopy' ~ 'persistence'
                   # captures tree-over classes
                   str_like(y_2013, 'Tree Canopy%') & str_like(y_2018, 'Tree Canopy%') ~ 'persistence'
                 , y_2013 == 'Tree Canopy' & y_2018 != 'Tree Canopy' ~ 'loss'
                 , y_2013 != 'Tree Canopy' & y_2018 == 'Tree Canopy' ~ 'gain'
                 , TRUE ~ 'not tree'
                 )
    )
    )

```


# 2 read in polygons
## A HOLC
```{r}

(holc <- st_read('output_tables/baci_holc_polygons_2024-02-20.gpkg', as_tibble = TRUE))

# double check
holc |> mapview()

# do we have a true unique id?
holc |> 
  st_drop_geometry() |> 
  distinct(area_id)

holc |> nrow()

```


## B census tracts
```{r}

tract_map <- st_read('../grand_challenges_large/tract_map.gpkg', as_tibble = TRUE) |> 
  mutate(GEOID = as.numeric(GEOID)) |>
  st_transform(st_crs(lcc))

# double check
tract_map |> mapview()

# do we have a true unique id?
tract_map |> 
  st_drop_geometry() |> 
  distinct(GEOID)

tract_map |> nrow()

# tract_map |> st_write('../grand_challenges_large/tract_map.gpkg')

```


# 3 summarise land cover via slow but effective for loop
## A HOLC
```{r eval=FALSE, include=FALSE}

n_jobs <- 7
shp <-
  holc |>
  tidylog::select(area_id) |>
  mutate(group = santoku::chop_equally(area_id, n_jobs, labels = santoku::lbl_seq(start = 'A'))) 

# checks
all.equal(nrow(shp), shp$area_id |> unique() |> length()) # yes!

# 2x check
shp |> st_drop_geometry() |> tabyl(group)



# kth loop dispatches jobs
# j is just a cheap progress bar
# i is the unique polygon loop
for(k in LETTERS[1:n_jobs]){
  job::job({
    tic()
    j <- 0 # initializes cheap progress bar
    for(i in shp |> filter(group == k) |> distinct(area_id) |> pull(area_id)){

      print(i)             # prints the unique (for troubleshooting)
      j <- j + 1; print(j) # prints the iterator

      # the work horse of the whole operation
      out <-
        terra::crop(lcc, shp[shp$area_id == i,]) |>
        terra::mask(shp[shp$area_id == i,]) |>
        terra::values() |>
        table()

      # Output is returned as a long-form data frame with a column for plot ID, pixel class, and pixel count.
      # Error catching code is included so that if there are no values in the circle (entirely outside raster)
      if (length(out) > 0) {
        data.frame(polygon_id = i, class = names(out), pixel_count = as.numeric(out)) |>
          data.table::fwrite(paste0('output_tables/lcc_summary_', Sys.Date(), '.csv') # PAY ATTENTION
                    , append = TRUE) # vital!
        } else {
          data.frame(polygon_id = i, class = character(0), pixel_count = numeric(0)) |> 
            data.table::fwrite(paste0('output_tables/lcc_summary_', Sys.Date(), '.csv') # PAY ATTENTION
                      , append = TRUE)
          }
      }; toc() #; beep() # end ith loop (the individual polygons)
  }) # end job k-th job
  }  # end all ~16 mins w 13 jobs (cores)

# did that work?
(lcc_summary <- read_csv('output_tables/lcc_summary_2024-02-20.csv') |> 
    rename(area_id = polygon_id))
    

# a double check
lcc_summary |> distinct(area_id) |> nrow() - shp |> nrow()
 
holc_pct_tc_2018 <- 
  lcc_summary |> 
  left_join(lcc_key, by = c('class' = 'ID')) |> 
  group_by(area_id) |> 
  mutate(area = sum(pixel_count)) |> 
  ungroup() |> 
  mutate(pct_area = 100*(pixel_count / area)) |> 
  filter(str_detect(y_2018, 'Tree')) |> # tabyl(y_2018) # gets tree canopy class only
  group_by(area_id) |> 
  summarise(pct_tc_18 = sum(pct_area))
  
holc_pct_tc_2018

# does this join back cleanly?
holc |> 
  left_join(holc_pct_tc_2018, by = 'area_id')

holc |> 
  left_join(holc_pct_tc_2018, by = 'area_id') |> 
  mapview(zcol = 'pct_tc_18')

# write out
holc_pct_tc_2018 |> 
  write_csv(paste0('output_tables/holc_pct_tc_2018_', Sys.Date(), '.csv'))

```


## B census tracts
```{r eval=FALSE, include=FALSE}

n_jobs <- 3
shp <-
  tract_map |>
  tidylog::select(GEOID) |>
  mutate(group = santoku::chop_equally(GEOID, n_jobs, labels = santoku::lbl_seq(start = 'A'))) 

# checks
all.equal(nrow(shp), shp$GEOID |> unique() |> length()) # yes!

# 2x check
shp |> st_drop_geometry() |> tabyl(group)



# kth loop dispatches jobs
# j is just a cheap progress bar
# i is the unique polygon loop
for(k in LETTERS[1:n_jobs]){
  job::job({
    tic()
    j <- 0 # initializes cheap progress bar
    for(i in shp |> filter(group == k) |> distinct(GEOID) |> pull(GEOID)){

      print(i)             # prints the unique (for troubleshooting)
      j <- j + 1; print(j) # prints the iterator

      # the work horse of the whole operation
      out <-
        terra::crop(lcc, shp[shp$GEOID == i,]) |>
        terra::mask(shp[shp$GEOID == i,]) |>
        terra::values() |>
        table()

      # Output is returned as a long-form data frame with a column for plot ID, pixel class, and pixel count.
      # Error catching code is included so that if there are no values in the circle (entirely outside raster)
      if (length(out) > 0) {
        data.frame(polygon_id = i, class = names(out), pixel_count = as.numeric(out)) |>
          data.table::fwrite(paste0('output_tables/lcc_summary_tracts_', Sys.Date(), '.csv') # PAY ATTENTION
                    , append = TRUE) # vital!
        } else {
          data.frame(polygon_id = i, class = character(0), pixel_count = numeric(0)) |> 
            data.table::fwrite(paste0('output_tables/lcc_summary_tracts_', Sys.Date(), '.csv') # PAY ATTENTION
                      , append = TRUE)
          }
      }; toc() #; beep() # end ith loop (the individual polygons)
  }) # end job k-th job
  }  # end all ~16 mins w 13 jobs (cores)


# did that work?
(lcc_summary_tracts <- read_csv('output_tables/lcc_summary_tracts_2025-04-21.csv') |> 
    rename(GEOID = polygon_id))
    

# a double check
lcc_summary_tracts |> distinct(GEOID) |> nrow() - shp |> nrow()
 
tract_pct_tc_2018 <- 
  lcc_summary_tracts |> 
  left_join(lcc_key, by = c('class' = 'ID')) |> 
  group_by(GEOID) |> 
  mutate(area = sum(pixel_count)) |> 
  ungroup() |> 
  mutate(pct_area = 100*(pixel_count / area)) |> 
  filter(str_detect(y_2018, 'Tree')) |> # tabyl(y_2018) # gets tree canopy class only
  group_by(GEOID) |> 
  summarise(pct_tc_18 = sum(pct_area))
  
tract_pct_tc_2018

# does this join back cleanly?
tract_map |> 
  left_join(tract_pct_tc_2018, by = 'GEOID')

tract_map |> 
  left_join(tract_pct_tc_2018, by = 'GEOID') |> 
  mapview(zcol = 'pct_tc_18')

# write out
tract_pct_tc_2018 |> 
  write_csv(paste0('output_tables/tract_pct_tc_2018_', Sys.Date(), '.csv'))

```

# end



