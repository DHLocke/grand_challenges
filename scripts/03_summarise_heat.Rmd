---
title: "03_summarise_heat"
author: "Kelsey McGurrin Dexter H. Locke Maggie Schaefer"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

  
## 0 set up: load libraries, custom functions, set defaults
```{r}

# load libraries
# packages we'll be using
packs <- c(
  'tidyverse'         # a must have!
  , 'tidylog'         # makes things very verbose for 2x checking 
  , 'magrittr'        # all of the pipes
  , 'janitor'         # cleans things up
  , 'sf'              # spatial support
  , 'tidycensus'      # Census access
  , 'mapview'         # webmaps
  , 'tictoc'          # times things
  , 'beepr'           # makes noises
  , 'tigris'          # get census shapefiles
  , 'santoku'         # divide data into nice groups
  , 'job'             # for organizing loops
  , 'terra'           # spatial analysis
  , 'raster'          # raster spatial
  )         

# check for all of the libraries
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

# load them
vapply(packs, library, character.only = TRUE, logical(1), logical.return = TRUE, quietly = TRUE)



# keep random things consistent
# set.seed(19870630) # needed?


# redlining colors
holc_pal <- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              #, '#A9A9A9'
              ) # dark gray)

holc_pal_f<- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              , '#A9A9A9'
              , '#000000')


# set custom function for getting spatial data
see_sf <- function(){
# what's in memory that are sf - spatial features?
keep(eapply(.GlobalEnv, class),      # gets the objects in the global environment
     ~ any(str_detect(., "sf"))) %>% # selects elements with sf in them
    names(.) %>% as.character(.)     # my simple features
}

see_sf() -> sf_in_memory

# what are the spatial references of those SF classes?
mget(sf_in_memory) %>% purrr::map(~st_crs(.x)$epsg) %>% unlist() #%>% View()


# # get file size

# custom function for "Not In"
`%nin%` <- Negate(`%in%`)


# fixes mapview
mapviewOptions(
    legend.pos = 'bottomleft'
  , layers.control.pos = 'topright'
  , fgb = FALSE
)

```


# 1 read in the land cover spatial reference system
```{r}

#(heat <- raster::raster('../grand_challenges_large/baltimore/temperature surfaces/bal_af.tif')) # Dexter path
(heat <- raster::raster('../grand_challenges_large/bal_af.tif')) # Kelsey path

# double checker
heat |> mapview::mapview()

```


# 2 read in polygons
## A HOLC
```{r}

(holc <- st_read('output_tables/baci_holc_polygons_2024-02-20.gpkg', as_tibble = TRUE) |> 
   st_transform(st_crs(heat))
 )

# double check
holc |> mapview()

# do we have a true unique id?
holc |> 
  st_drop_geometry() |> 
  distinct(area_id)

holc |> nrow()

```


## B census tracts
```{r}

# # no need to read in here, since we have it downloaded. Two roads, same
# tract_map<-
#   tracts(
#   state = 'Maryland',
#   county = 'Baltimore city',
#   cb = FALSE,
#   resolution = "500k",
#   year = 2020
# ) |>
#   st_transform(crs = st_crs(heat))

tract_map <- st_read('../grand_challenges_large/tract_map.gpkg', as_tibble = TRUE) |> 
  mutate(GEOID = as.numeric(GEOID))

# double check
tract_map |> mapview()

# do we have a true unique id?
tract_map |> 
  st_drop_geometry() |> 
  distinct(GEOID)

tract_map |> nrow()

# tract_map |> st_write('../grand_challenges_large/tract_map.gpkg')

```


# 3 heat summaries
## A HOLC via slow but effective for loop
```{r eval=FALSE, include=FALSE}
n_jobs <- 7
shp <-
  holc |>
  tidylog::select(area_id) |>
  mutate(group = santoku::chop_equally(area_id, n_jobs, labels = santoku::lbl_seq(start = 'A'))) 

# checks
all.equal(nrow(shp), shp$area_id |> unique() |> length()) # yes!

# 2x check
shp |> st_drop_geometry() |> tabyl(group)



# kth loop dispatches jobs
# j is just a cheap progress bar
# i is the unique polygon loop
for(k in LETTERS[1:n_jobs]){
  job::job({
    tic()
    j <- 0 # initializes cheap progress bar
    for(i in shp |> filter(group == k) |> distinct(area_id) |> pull(area_id)){

      print(i)             # prints the unique (for troubleshooting)
      j <- j + 1; print(j) # prints the iterator

      # the work horse of the whole operation
      out <-
        terra::crop(heat, shp[shp$area_id == i,]) |>
        terra::mask(shp[shp$area_id == i,]) |>
        terra::values() |>
        mean(na.rm = TRUE)

      # Output is returned as a long-form data frame with a column for plot ID, pixel class, and pixel count.
      # Error catching code is included so that if there are no values in the circle (entirely outside raster)
      data.frame(polygon_id = i, mean_temp_C = as.numeric(out)) |>
        data.table::fwrite(paste0('output_tables/heat_summary_', Sys.Date(), '.csv') # PAY ATTENTION
                           , append = TRUE) # vital!

      }; toc() #; beep() # end ith loop (the individual polygons)
  }) # end job k-th job
  }  # end all ~16 mins w 13 jobs (cores)
```

### i read those summaries back in
```{r eval=FALSE, include=FALSE}
# did that work?
(heat_summary <- read_csv('output_tables/heat_summary_2024-02-27.csv') |> 
    rename(area_id = polygon_id))
    

# a double check
heat_summary |> distinct(area_id) |> nrow() - shp |> nrow()
 

# does this join back cleanly?
holc |> 
  left_join(heat_summary, by = 'area_id')

holc |> 
  left_join(heat_summary, by = 'area_id') |> 
  mapview(zcol = 'mean_temp_C')

```


# B. Census tracts via slow but effective for loop
```{r eval=FALSE, include=FALSE}
n_jobs <- 3
shp <-
  tract_map |>
  tidylog::select(GEOID) |>
  mutate(group = santoku::chop_equally(GEOID, n_jobs, labels = santoku::lbl_seq(start = 'A'))) 

# checks
all.equal(nrow(shp), shp$GEOID |> unique() |> length()) # yes!

# 2x check
shp |> st_drop_geometry() |> tabyl(group)



# kth loop dispatches jobs
# j is just a cheap progress bar
# i is the unique polygon loop
for(k in LETTERS[1:n_jobs]){
  job::job({
    tic()
    j <- 0 # initializes cheap progress bar
    for(i in shp |> filter(group == k) |> distinct(GEOID) |> pull(GEOID)){

      print(i)             # prints the unique (for troubleshooting)
      j <- j + 1; print(j) # prints the iterator

      # the work horse of the whole operation
      out <-
        terra::crop(heat, shp[shp$GEOID == i,]) |>
        terra::mask(shp[shp$GEOID == i,]) |>
        terra::values() |>
        mean(na.rm = TRUE)

      # Output is returned as a long-form data frame with a column for plot ID, pixel class, and pixel count.
      # Error catching code is included so that if there are no values in the circle (entirely outside raster)
      data.frame(polygon_id = i, mean_temp_C = as.numeric(out)) |>
        data.table::fwrite(paste0('output_tables/heat_summary_tracts_', Sys.Date(), '.csv') # PAY ATTENTION
                           , append = TRUE) # vital!

      }; toc() #; beep() # end ith loop (the individual polygons)
  }) # end job k-th job
  }  # end all less than 3 seconds with 3 jobs (cores)
```

### i read tract summaries back in
```{r eval=FALSE, include=FALSE}
# did that work?
(heat_summary_tract <- read_csv('output_tables/heat_summary_tracts_2025-04-10.csv') |> 
    rename(GEOID = polygon_id))

# # tract_map wants GEOID to be a character so let's fix that
# tract_map <- transform(tract_map, GEOID = as.numeric(GEOID))
    

# a double check
heat_summary_tract |> distinct(GEOID) |> nrow() - shp |> nrow()
 

# does this join back cleanly?
tract_map |> 
  left_join(heat_summary_tract, by = 'GEOID')

tract_map |> 
  left_join(heat_summary_tract, by = 'GEOID') |> 
  mapview(zcol = 'mean_temp_C')

```


# 4 heat: raster to points
## A buffers for 2024 tree list
```{r}

# this is borrowed from '07_schaefer_poster_map.Rmd'
trees_sf <- 
  # wanted a trees file, used csv from script above
  read_csv("output_tables/GC_cleaned_survey_photosynq_2024_notes_split.csv") |> 
  st_as_sf(coords = c("long", "lat"), crs = 4326) |> # made spatial
  st_transform(crs = st_crs(heat)) # reprojected to match heat (heat is large, points small)

# sanity checks
trees_sf |> glimpse()
trees_sf |> mapview(zcol = 'SPP') + mapview(heat)

# extract temperature from the raster to the points.
trees_sf <-
  trees_sf |> 
    mutate(temp_C = raster::extract(heat, trees_sf)) # if a lot of points, consider saving *.csv

# double checks
trees_sf |> glimpse()

trees_sf |> mapview(zcol = 'temp_C') + mapview(heat)

m1 <- trees_sf |> mapview(zcol = 'temp_C', layer.name = 'raster')
m2 <- trees_sf |> mapview(zcol = 'Leaf Temperature', layer.name = 'Leaf<br>Temp.')
m3 <- trees_sf |> mapview(zcol = 'Ambient Temperature', layer.name = 'Ambient<br>Temp.')

leafsync::sync(m1, m2, m3)

# how are each of these measures of temperature distributed?
trees_sf |> 
  st_drop_geometry() |> 
  select(Burghardt_ID, temp_C, mean_temp_C, `Leaf Temperature`, `Ambient Temperature`) |> 
  pivot_longer(-Burghardt_ID) |> 
  ggplot(aes(value)) +
  geom_density() + 
  facet_wrap(~name) + 
  theme_bw(16) +
  NULL

# how do these temperature measures co-vary?
trees_sf |> 
  st_drop_geometry() |> 
  select(Burghardt_ID, temp_C, mean_temp_C, `Leaf Temperature`, `Ambient Temperature`) |> 
  pivot_longer(-c(Burghardt_ID, temp_C)) |> 
  ggplot(aes(temp_C, value)) +
  geom_point() + 
  geom_smooth() +
  geom_smooth(method = 'lm', color = 'red') +
  facet_wrap(~name) + 
  theme_bw(16) +
  NULL

# how do these temperature measures correlate?
trees_sf |> 
  st_drop_geometry() |> 
  select(temp_C, mean_temp_C, `Leaf Temperature`, `Ambient Temperature`) |> 
  correlation::correlation()

trees_sf |> 
  st_drop_geometry() |> 
  select(temp_C, mean_temp_C, `Leaf Temperature`, `Ambient Temperature`) |> 
  correlation::correlation() |> 
  summary()


## With a buffer around the tree
st_crs(trees_sf)$units # check units
trees_sf_buffered <- st_buffer(trees_sf, dist = 15) #make 15 meter buffer

# sanity checks
trees_sf_buffered |> glimpse()
trees_sf_buffered |> mapview(zcol = 'SPP') + mapview(heat)

# extract temp from raster to buffer
n_jobs <- 3
shp <-
  trees_sf_buffered |>
  tidylog::select(Burghardt_ID) |>
  mutate(group = santoku::chop_equally(Burghardt_ID, n_jobs, labels = santoku::lbl_seq(start = 'A'))) 

# checks
all.equal(nrow(shp), shp$Burghardt_ID |> unique() |> length()) # yes!

# 2x check
shp |> st_drop_geometry() |> tabyl(group)



# kth loop dispatches jobs
# j is just a cheap progress bar
# i is the unique polygon loop
for(k in LETTERS[1:n_jobs]){
  job::job({
    tic()
    j <- 0 # initializes cheap progress bar
    for(i in shp |> filter(group == k) |> distinct(Burghardt_ID) |> pull(Burghardt_ID)){

      print(i)             # prints the unique (for troubleshooting)
      j <- j + 1; print(j) # prints the iterator

      # the work horse of the whole operation
      out <-
        terra::crop(heat, shp[shp$Burghardt_ID == i,]) |>
        terra::mask(shp[shp$Burghardt_ID == i,]) |>
        terra::values() |>
        mean(na.rm = TRUE)

      # Output is returned as a long-form data frame with a column for plot ID, pixel class, and pixel count.
      # Error catching code is included so that if there are no values in the circle (entirely outside raster)
      data.frame(polygon_id = i, buffer_temp_C = as.numeric(out)) |>
        data.table::fwrite(paste0('output_tables/heat_summary_buffer_', Sys.Date(), '.csv') # PAY ATTENTION
                           , append = TRUE) # vital!

      }; toc() #; beep() # end ith loop (the individual polygons)
  }) # end job k-th job
  }  # end all less than 3 seconds with 3 jobs (cores)

(heat_summary_buffer <- read_csv('output_tables/heat_summary_buffer_2025-04-30.csv') |> 
    rename(Burghardt_ID = polygon_id))

# a double check
heat_summary_buffer |> distinct(Burghardt_ID) |> nrow() - shp |> nrow()
 

# does this join back cleanly?
trees_sf_buffered |> 
  left_join(heat_summary_buffer, by = 'Burghardt_ID')

trees_sf_buffered |> 
  left_join(heat_summary_buffer, by = 'Burghardt_ID') |> 
  mapview(zcol = 'buffer_temp_C')


# export csv for picking 2025 data logger locations
trees<- read_csv("output_tables/GC_cleaned_survey_photosynq_2024_notes_split.csv") |> dplyr::select(Burghardt_ID,lat,long)
trees2<-left_join(trees_sf_buffered,trees)
loggers<-
  left_join(trees2,heat_summary_buffer, by = 'Burghardt_ID') |>
  st_drop_geometry()

write_csv(loggers,paste0('output_tables/candidate_logger_trees_', Sys.Date(), '.csv'),append=F)

```

## B buffer for 2025 tree list
```{r}

# this is borrowed from '07_schaefer_poster_map.Rmd'
trees_sf <- 
  # wanted a trees file, used csv from script above
  read_csv("../grand_challenges_large/candidate_street_trees_2025-05-07.csv") |> 
  st_as_sf(coords = c("long", "lat"), crs = 4326) |> # made spatial
  st_transform(crs = st_crs(heat)) # reprojected to match heat (heat is large, points small)

# sanity checks
trees_sf |> glimpse()
trees_sf |> mapview(zcol = 'SPP') + mapview(heat)

# extract temperature from the raster to the points.
trees_sf <-
  trees_sf |> 
    mutate(temp_C = raster::extract(heat, trees_sf)) # if a lot of points, consider saving *.csv

# double checks
trees_sf |> glimpse()

trees_sf |> mapview(zcol = 'temp_C') + mapview(heat)


## With a buffer around the tree
st_crs(trees_sf)$units # check units
trees_sf_buffered <- st_buffer(trees_sf, dist = 15) #make 15 meter buffer

# sanity checks
trees_sf_buffered |> glimpse()
trees_sf_buffered |> mapview(zcol = 'SPP') + mapview(heat)

# extract temp from raster to buffer
n_jobs <- 3
shp <-
  trees_sf_buffered |>
  tidylog::select(Burghardt_ID) |>
  mutate(group = santoku::chop_equally(Burghardt_ID, n_jobs, labels = santoku::lbl_seq(start = 'A'))) 

# checks
all.equal(nrow(shp), shp$Burghardt_ID |> unique() |> length()) # yes!

# 2x check
shp |> st_drop_geometry() |> tabyl(group)



# kth loop dispatches jobs
# j is just a cheap progress bar
# i is the unique polygon loop
for(k in LETTERS[1:n_jobs]){
  job::job({
    tic()
    j <- 0 # initializes cheap progress bar
    for(i in shp |> filter(group == k) |> distinct(Burghardt_ID) |> pull(Burghardt_ID)){

      print(i)             # prints the unique (for troubleshooting)
      j <- j + 1; print(j) # prints the iterator

      # the work horse of the whole operation
      out <-
        terra::crop(heat, shp[shp$Burghardt_ID == i,]) |>
        terra::mask(shp[shp$Burghardt_ID == i,]) |>
        terra::values() |>
        mean(na.rm = TRUE)

      # Output is returned as a long-form data frame with a column for plot ID, pixel class, and pixel count.
      # Error catching code is included so that if there are no values in the circle (entirely outside raster)
      data.frame(polygon_id = i, buffer_temp_C = as.numeric(out)) |>
        data.table::fwrite(paste0('output_tables/heat_summary_buffer_', Sys.Date(), '.csv') # PAY ATTENTION
                           , append = TRUE) # vital!

      }; toc() #; beep() # end ith loop (the individual polygons)
  }) # end job k-th job
  }  # end all less than 3 seconds with 3 jobs (cores)

(heat_summary_buffer <- read_csv('output_tables/heat_summary_buffer_2025-05-07.csv') |> 
    rename(Burghardt_ID = polygon_id))

# a double check
heat_summary_buffer |> distinct(Burghardt_ID) |> nrow() - shp |> nrow()
 

# does this join back cleanly?
trees_sf_buffered |> 
  left_join(heat_summary_buffer, by = 'Burghardt_ID')

trees_sf_buffered |> 
  left_join(heat_summary_buffer, by = 'Burghardt_ID') |> 
  mapview(zcol = 'buffer_temp_C')

maggie_trees<-trees_sf_buffered |> 
  st_join(trees_sf,by='Burghardt_ID')

trees<- read_csv("../grand_challenges_large/candidate_street_trees_2025-05-07.csv") |> dplyr::select(Burghardt_ID,lat,long)
trees2<-left_join(trees_sf_buffered,trees)
trees3<-
  left_join(trees2,heat_summary_buffer, by = 'Burghardt_ID') |>
  st_drop_geometry()

# export as csv
write_csv(trees3,paste0('../grand_challenges_large/candidate_street_trees_', Sys.Date(), '.csv'),append=F)

```



# end



